{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e455da6-5230-4055-904f-ea90b77de971",
   "metadata": {},
   "source": [
    "<h2> MNIST Digit Recognition - CNN - Tensorflow Implementation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0869c2-8825-42b7-a4bf-c512b6a933c2",
   "metadata": {},
   "source": [
    "<b> About the Project </b>\n",
    "<br>\n",
    "<p> \n",
    "In this project we will be implementing a Convolutional Neural Network (CNN) with the aim to classify the MNIST Handwritten Digits (0-9) into their respective target classes - 0 to 9. This project can be considered the basics of neural networks and deep neural networks and also as the basics of computer vision as well. \n",
    "\n",
    "<br>\n",
    "\n",
    "<b> Aim of this project </b>\n",
    "- Implement a CNN network, train it on MNIST dataset and save the high performing network\n",
    "- Preprocess and normalize the dataset before training.\n",
    "- Train an MLP model, CNN models with 1, 2 and 3 CNN layers respectively and compare the performance .\n",
    "\n",
    "<b> Why CNN is being used </b>\n",
    "- CNNs can capture patterns like edges, shapes, and textures.\n",
    "- In this project we are using 3 convolutional layers, 1st to detect edges, 2nd to maybe detect curves or corners and final for loops or other high level structures\n",
    "- They are translation invariant — they can detect a digit even if it’s slightly shifted - so even if input data is augmented by a bit, unlike machine learning models, these can detect the digit with ease. So the extra data augmentation in the preprocessing steps is not needed prior to training. \n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "86895918-ae90-4b96-8774-007924251e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed4e39-78aa-492c-8333-a7f0b6de168c",
   "metadata": {},
   "source": [
    "<h4> About the MNIST Dataset and Import </h4>\n",
    "\n",
    "Here we will be importing the dataset from Tensorflow's built-in datasets. \n",
    "\n",
    "<b> About the MNIST Dataset </b>\n",
    "- MNIST (Modified National Institute of Standards and Technology) consists of 70000 images of handwritten digits. This dataset is considered the benchmark dataset in machine learning.\n",
    "- Formed by collected 28 * 28 pixel images of digits written by 250 different people.\n",
    "- Total Images: 70000, out of which 60000 is for training and 10000 is used for testing.\n",
    "- The target labels in this dataset range from 0 - 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69cef811-2df2-4d85-a047-d598ee11f0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Import \n",
    "\n",
    "(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train_full.shape, y_train_full.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6af7d364-5141-401f-8451-c48187e3faf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing Sample Images of Each Class\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 5, sharex = True, sharey = True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    digit = x_train_full[y_train_full == i][0]\n",
    "    ax[i].imshow(digit, cmap = \"Greys\")\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944b2c8-46cb-455a-b6d3-148df70eacba",
   "metadata": {},
   "source": [
    "<h4> Normalizing the Dataset </h4>\n",
    "\n",
    "- The original pixel values in MNIST range from 0 to 255.\n",
    "- Neural networks perform better when inputs are in a smaller, consistent range, typically between 0 and 1.\n",
    "- This helps:\n",
    "    - Speed up convergence\n",
    "    - Improve numerical stability\n",
    "    - Prevent issues with gradient vanishing/exploding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b40d545a-ba27-464e-a523-4ced21c4ab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28) (55000,) (5000, 28, 28) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the Dataset to 0 - 1 range. \n",
    "# Then shuffling and splitting into train, validation and test sets.\n",
    "np.random.seed(42)\n",
    "shuffle_indices = np.random.permutation(60000)\n",
    "x_train_full, y_train_full = x_train_full[shuffle_indices], y_train_full[shuffle_indices]\n",
    "\n",
    "x_train_full, x_test = x_train_full / 255, x_test / 255\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 5000, random_state = 42, stratify = y_train_full)\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d77c7-f7b5-4f55-a99b-62471a48ddef",
   "metadata": {},
   "source": [
    "<h4> Implementing a simple MLP Model </h4>\n",
    "\n",
    "This is only being done to compare the performance against our CNN Models.  \n",
    "\n",
    "\n",
    "<b> ** Note ** </b>\n",
    "Last layer activation is set to softmax at all times because we are dealing with multicass targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd879ed0-eafb-4397-b45d-fe15555e081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing MLP model\n",
    "\n",
    "mlp_model = keras.models.Sequential([\n",
    "    keras.Input(shape = (28, 28)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(500, activation = \"relu\"),\n",
    "    keras.layers.Dense(250, activation = \"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "676a34fa-aa0a-4677-b62f-5cb49f7329f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">392,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">125,250</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,510</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │         \u001b[38;5;34m392,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)                 │         \u001b[38;5;34m125,250\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,510\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">520,260</span> (1.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m520,260\u001b[0m (1.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">520,260</span> (1.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m520,260\u001b[0m (1.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27bac9b0-de4e-4cc9-9469-98cb5c1a01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f211f7fe-75c7-48e1-850d-924f6b2bc50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8475 - loss: 0.5438 - val_accuracy: 0.9560 - val_loss: 0.1464\n",
      "Epoch 2/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9658 - loss: 0.1130 - val_accuracy: 0.9710 - val_loss: 0.1038\n",
      "Epoch 3/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9812 - loss: 0.0627 - val_accuracy: 0.9720 - val_loss: 0.0909\n",
      "Epoch 4/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0433 - val_accuracy: 0.9756 - val_loss: 0.0866\n",
      "Epoch 5/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0290 - val_accuracy: 0.9768 - val_loss: 0.0819\n",
      "Epoch 6/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0209 - val_accuracy: 0.9784 - val_loss: 0.0870\n",
      "Epoch 7/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0144 - val_accuracy: 0.9796 - val_loss: 0.0801\n",
      "Epoch 8/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0086 - val_accuracy: 0.9758 - val_loss: 0.1012\n",
      "Epoch 9/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0090 - val_accuracy: 0.9766 - val_loss: 0.0967\n",
      "Epoch 10/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9802 - val_loss: 0.0893\n",
      "Epoch 11/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9768 - val_loss: 0.1049\n",
      "Epoch 12/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0093 - val_accuracy: 0.9772 - val_loss: 0.1077\n",
      "Epoch 13/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0121 - val_accuracy: 0.9788 - val_loss: 0.0970\n",
      "Epoch 14/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0084 - val_accuracy: 0.9766 - val_loss: 0.1056\n",
      "Epoch 15/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0107 - val_accuracy: 0.9802 - val_loss: 0.1054\n",
      "Epoch 16/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9798 - val_loss: 0.1095\n",
      "Epoch 17/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9806 - val_loss: 0.1033\n",
      "Epoch 18/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9822 - val_loss: 0.1169\n",
      "Epoch 19/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9818 - val_loss: 0.1108\n",
      "Epoch 20/20\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 7.2963e-04 - val_accuracy: 0.9834 - val_loss: 0.1063\n"
     ]
    }
   ],
   "source": [
    "mlp_model_history = mlp_model.fit(x_train, y_train, epochs = 20, batch_size = 256, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8348162c-85aa-4f05-a675-9a4a9a74b347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0918     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07555942237377167, 0.9840999841690063]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fe18f-e9f5-46c1-b0ef-e92b43a77aa1",
   "metadata": {},
   "source": [
    "### CNN Model 1 Architecture Description\n",
    "\n",
    " Below is a detailed explanation of the architecture:\n",
    "\n",
    "---\n",
    "\n",
    "#### Input Shape\n",
    "- The input shape is `(28, 28, 1)` representing 28×28 grayscale images.\n",
    "- This matches the MNIST format and prepares the data for convolutional layers.\n",
    "\n",
    "---\n",
    "\n",
    "####  Convolutional Layers (Feature Extraction)\n",
    "- The first block contains **two Conv2D layers** with:\n",
    "  - `32 filters`, `3x3` kernel size\n",
    "  - **ReLU activation** and `\"same\"` padding (to preserve spatial size)\n",
    "- These layers help extract low-level features such as edges and corners.\n",
    "\n",
    "---\n",
    "\n",
    "#### Max Pooling\n",
    "- A `MaxPooling2D` layer with `pool_size=2` reduces the spatial size (28×28 → 14×14).\n",
    "- This helps reduce computation and improves generalization.\n",
    "\n",
    "---\n",
    "\n",
    "#### Second Convolutional Block\n",
    "- Another two Conv2D layers with:\n",
    "  - `64 filters`, `3x3` kernel size\n",
    "  - `\"same\"` padding and **ReLU** activation\n",
    "- Followed by another MaxPooling2D layer which reduces the size further (14×14 → 7×7).\n",
    "- These layers extract more complex patterns, such as full digit shapes.\n",
    "\n",
    "---\n",
    "\n",
    "#### Flatten Layer\n",
    "- The output of the final pooling layer is flattened into a 1D vector (from 7×7×64 = 3136) to feed into the dense layers.\n",
    "\n",
    "---\n",
    "\n",
    "####  Dropout (Regularization)\n",
    "- `Dropout(0.5)` is used twice to randomly deactivate 50% of neurons during training.\n",
    "- This helps prevent overfitting and improves generalization.\n",
    "\n",
    "---\n",
    "\n",
    "#### Fully Connected Layers\n",
    "- Two dense (fully connected) layers:\n",
    "  - `Dense(300)` and `Dense(150)` with **ReLU activation**\n",
    "- These layers learn high-level representations from the extracted features.\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Layer\n",
    "- `Dense(10, activation='softmax')` outputs probabilities for each of the 10 digit classes (0–9).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c10389b-f111-4862-adb2-e9dd76423988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing CNN Model \n",
    "\n",
    "cnn_x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "cnn_x_val = x_val.reshape(-1, 28, 28, 1)\n",
    "cnn_x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "cnn_model = keras.models.Sequential([\n",
    "    keras.Input(shape = (28,28, 1)),\n",
    "    keras.layers.Conv2D(32, kernel_size = (3,3), activation = \"relu\", padding = \"same\"),\n",
    "    keras.layers.Conv2D(32, kernel_size = (3,3), activation = \"relu\", padding = \"same\"),\n",
    "    keras.layers.MaxPool2D(pool_size = 2),\n",
    "    keras.layers.Conv2D(64, kernel_size = (3,3), activation = \"relu\", padding = \"same\"),\n",
    "    keras.layers.Conv2D(64, kernel_size = (3,3), activation = \"relu\", padding = \"same\"),\n",
    "    keras.layers.MaxPool2D(pool_size = 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(300, activation = \"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(150, activation = \"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\")\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "661ddc0d-40e0-448e-8a00-9536064a0c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">941,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">45,150</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,510</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │         \u001b[38;5;34m941,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │          \u001b[38;5;34m45,150\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,510\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,752</span> (4.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,052,752\u001b[0m (4.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,752</span> (4.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,052,752\u001b[0m (4.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c7f1a4b-88d5-4b89-a327-091a761b5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d19ffb7-c1e4-4c07-91df-56e69130ef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.8387 - loss: 0.4816 - val_accuracy: 0.9802 - val_loss: 0.0666\n",
      "Epoch 2/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 64ms/step - accuracy: 0.9772 - loss: 0.0788 - val_accuracy: 0.9882 - val_loss: 0.0454\n",
      "Epoch 3/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 65ms/step - accuracy: 0.9819 - loss: 0.0586 - val_accuracy: 0.9888 - val_loss: 0.0358\n",
      "Epoch 4/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 64ms/step - accuracy: 0.9859 - loss: 0.0466 - val_accuracy: 0.9856 - val_loss: 0.0493\n",
      "Epoch 5/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 64ms/step - accuracy: 0.9871 - loss: 0.0424 - val_accuracy: 0.9882 - val_loss: 0.0398\n",
      "Epoch 6/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 66ms/step - accuracy: 0.9877 - loss: 0.0412 - val_accuracy: 0.9908 - val_loss: 0.0381\n",
      "Epoch 7/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 66ms/step - accuracy: 0.9899 - loss: 0.0320 - val_accuracy: 0.9916 - val_loss: 0.0345\n",
      "Epoch 8/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 68ms/step - accuracy: 0.9901 - loss: 0.0317 - val_accuracy: 0.9924 - val_loss: 0.0306\n",
      "Epoch 9/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 66ms/step - accuracy: 0.9909 - loss: 0.0285 - val_accuracy: 0.9916 - val_loss: 0.0402\n",
      "Epoch 10/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 65ms/step - accuracy: 0.9919 - loss: 0.0272 - val_accuracy: 0.9920 - val_loss: 0.0306\n",
      "Epoch 11/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 66ms/step - accuracy: 0.9928 - loss: 0.0247 - val_accuracy: 0.9934 - val_loss: 0.0303\n",
      "Epoch 12/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 66ms/step - accuracy: 0.9927 - loss: 0.0235 - val_accuracy: 0.9914 - val_loss: 0.0347\n",
      "Epoch 13/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 66ms/step - accuracy: 0.9929 - loss: 0.0224 - val_accuracy: 0.9934 - val_loss: 0.0304\n",
      "Epoch 14/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 67ms/step - accuracy: 0.9940 - loss: 0.0184 - val_accuracy: 0.9936 - val_loss: 0.0319\n",
      "Epoch 15/15\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 66ms/step - accuracy: 0.9941 - loss: 0.0182 - val_accuracy: 0.9940 - val_loss: 0.0283\n"
     ]
    }
   ],
   "source": [
    "cnn_history = cnn_model.fit(x_train, y_train, epochs = 15, batch_size = 64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f23a2c75-05cc-4d31-b992-dbbec4b498ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0193 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01602880470454693, 0.9955999851226807]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e20e0-cb33-498b-9c96-717749669767",
   "metadata": {},
   "source": [
    "### CNN Model 1 Architecture Description\n",
    "\n",
    " Below is a detailed explanation of the architecture:\n",
    "\n",
    "---\n",
    "\n",
    "#### Input Shape\n",
    "- The input shape is `(28, 28, 1)` representing 28×28 grayscale images.\n",
    "- This matches the MNIST format and prepares the data for convolutional layers.\n",
    "\n",
    "---\n",
    "\n",
    "####  Convolutional Layers (Feature Extraction)\n",
    "- The first block contains **two Conv2D layers** with:\n",
    "  - `32 filters`, `3x3` kernel size\n",
    "  - **ReLU activation** and `\"same\"` padding (to preserve spatial size)\n",
    "- These layers help extract low-level features such as edges and corners.\n",
    "\n",
    "---\n",
    "\n",
    "#### Max Pooling\n",
    "- A `MaxPooling2D` layer with `pool_size=2` reduces the spatial size (28×28 → 14×14).\n",
    "- This helps reduce computation and improves generalization.\n",
    "\n",
    "---\n",
    "\n",
    "#### Second Convolutional Block\n",
    "- Another two Conv2D layers with:\n",
    "  - `64 filters`, `3x3` kernel size\n",
    "  - `\"same\"` padding and **ReLU** activation\n",
    "- Followed by another MaxPooling2D layer which reduces the size further (14×14 → 7×7).\n",
    "- These layers extract more complex patterns, such as full digit shapes.\n",
    "\n",
    "---\n",
    "\n",
    "#### Flatten Layer\n",
    "- The output of the final pooling layer is flattened into a 1D vector (from 7×7×64 = 3136) to feed into the dense layers.\n",
    "\n",
    "---\n",
    "\n",
    "####  Dropout (Regularization)\n",
    "- `Dropout(0.5)` is used twice to randomly deactivate 50% of neurons during training.\n",
    "- This helps prevent overfitting and improves generalization.\n",
    "\n",
    "---\n",
    "\n",
    "#### Fully Connected Layers\n",
    "- Two dense (fully connected) layers:\n",
    "  - `Dense(300)` and `Dense(150)` with **ReLU activation**\n",
    "- These layers learn high-level representations from the extracted features.\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Layer\n",
    "- `Dense(10, activation='softmax')` outputs probabilities for each of the 10 digit classes (0–9).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "25cad9bc-2cca-4b89-8753-6ed79b3131f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 83ms/step - accuracy: 0.8065 - loss: 0.6239 - val_accuracy: 0.9808 - val_loss: 0.0751 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 82ms/step - accuracy: 0.9706 - loss: 0.1025 - val_accuracy: 0.9844 - val_loss: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 85ms/step - accuracy: 0.9781 - loss: 0.0741 - val_accuracy: 0.9864 - val_loss: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 86ms/step - accuracy: 0.9823 - loss: 0.0605 - val_accuracy: 0.9856 - val_loss: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 88ms/step - accuracy: 0.9857 - loss: 0.0490 - val_accuracy: 0.9894 - val_loss: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 84ms/step - accuracy: 0.9872 - loss: 0.0455 - val_accuracy: 0.9868 - val_loss: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 86ms/step - accuracy: 0.9894 - loss: 0.0393 - val_accuracy: 0.9904 - val_loss: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 86ms/step - accuracy: 0.9889 - loss: 0.0399 - val_accuracy: 0.9898 - val_loss: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 88ms/step - accuracy: 0.9894 - loss: 0.0378 - val_accuracy: 0.9894 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 87ms/step - accuracy: 0.9901 - loss: 0.0314 - val_accuracy: 0.9864 - val_loss: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 83ms/step - accuracy: 0.9930 - loss: 0.0247 - val_accuracy: 0.9930 - val_loss: 0.0292 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 84ms/step - accuracy: 0.9937 - loss: 0.0193 - val_accuracy: 0.9924 - val_loss: 0.0286 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 84ms/step - accuracy: 0.9948 - loss: 0.0175 - val_accuracy: 0.9920 - val_loss: 0.0303 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 85ms/step - accuracy: 0.9957 - loss: 0.0153 - val_accuracy: 0.9920 - val_loss: 0.0341 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 86ms/step - accuracy: 0.9950 - loss: 0.0166 - val_accuracy: 0.9948 - val_loss: 0.0232 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 86ms/step - accuracy: 0.9963 - loss: 0.0122 - val_accuracy: 0.9946 - val_loss: 0.0297 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 85ms/step - accuracy: 0.9959 - loss: 0.0133 - val_accuracy: 0.9918 - val_loss: 0.0363 - learning_rate: 5.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 85ms/step - accuracy: 0.9950 - loss: 0.0152 - val_accuracy: 0.9940 - val_loss: 0.0260 - learning_rate: 5.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 85ms/step - accuracy: 0.9965 - loss: 0.0111 - val_accuracy: 0.9950 - val_loss: 0.0227 - learning_rate: 2.5000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 83ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 0.9954 - val_loss: 0.0227 - learning_rate: 2.5000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 84ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.9954 - val_loss: 0.0248 - learning_rate: 2.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 84ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9958 - val_loss: 0.0243 - learning_rate: 2.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 84ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9964 - val_loss: 0.0202 - learning_rate: 1.2500e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 90ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9956 - val_loss: 0.0253 - learning_rate: 1.2500e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 86ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.9964 - val_loss: 0.0226 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 86ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.9958 - val_loss: 0.0249 - learning_rate: 1.2500e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 86ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9958 - val_loss: 0.0248 - learning_rate: 6.2500e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 87ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9960 - val_loss: 0.0237 - learning_rate: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, callbacks\n",
    "\n",
    "model = models.Sequential([\n",
    "    keras.Input(shape=(28,28,1)),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    \n",
    "    layers.Conv2D(32, (3,3), padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(300, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(150, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "early_stopper = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Fit\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data = (x_val, y_val),\n",
    "                    epochs=30,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[lr_scheduler, early_stopper])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2623a456-ad36-4494-89ac-1c9d9f8e2375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9957 - loss: 0.0153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013720777817070484, 0.9962000250816345]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "56dce182-5b75-42c2-aee5-3dac04aadded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 83ms/step - accuracy: 0.8286 - loss: 0.5668 \n",
      "Epoch 2/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 83ms/step - accuracy: 0.9712 - loss: 0.1031 \n",
      "Epoch 3/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 82ms/step - accuracy: 0.9786 - loss: 0.0762 \n",
      "Epoch 4/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 83ms/step - accuracy: 0.9827 - loss: 0.0624 \n",
      "Epoch 5/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 82ms/step - accuracy: 0.9857 - loss: 0.0477 \n",
      "Epoch 6/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 83ms/step - accuracy: 0.9872 - loss: 0.0484 \n",
      "Epoch 7/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 82ms/step - accuracy: 0.9891 - loss: 0.0384 \n",
      "Epoch 8/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 82ms/step - accuracy: 0.9892 - loss: 0.0381 \n",
      "Epoch 9/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 80ms/step - accuracy: 0.9893 - loss: 0.0369 \n",
      "Epoch 10/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 82ms/step - accuracy: 0.9910 - loss: 0.0329 \n",
      "Epoch 11/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 80ms/step - accuracy: 0.9916 - loss: 0.0297 \n",
      "Epoch 12/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 80ms/step - accuracy: 0.9917 - loss: 0.0281 \n",
      "Epoch 13/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 80ms/step - accuracy: 0.9921 - loss: 0.0266 \n",
      "Epoch 14/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 81ms/step - accuracy: 0.9928 - loss: 0.0262 \n",
      "Epoch 15/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 81ms/step - accuracy: 0.9935 - loss: 0.0215 \n",
      "Epoch 16/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 81ms/step - accuracy: 0.9936 - loss: 0.0217 \n",
      "Epoch 17/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 82ms/step - accuracy: 0.9937 - loss: 0.0211 \n",
      "Epoch 18/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 85ms/step - accuracy: 0.9942 - loss: 0.0193 \n",
      "Epoch 19/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 86ms/step - accuracy: 0.9947 - loss: 0.0197 \n",
      "Epoch 20/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 86ms/step - accuracy: 0.9949 - loss: 0.0163 \n",
      "Epoch 21/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 85ms/step - accuracy: 0.9947 - loss: 0.0199 \n",
      "Epoch 22/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 87ms/step - accuracy: 0.9954 - loss: 0.0151 \n",
      "Epoch 23/23\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 89ms/step - accuracy: 0.9954 - loss: 0.0151 \n"
     ]
    }
   ],
   "source": [
    "# training the model on full data and re-evaluating \n",
    "\n",
    "full_model_3_layers = keras.models.clone_model(model)\n",
    "full_model_3_layers.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_full_train = full_model_3_layers.fit(x_train_full, y_train_full,\n",
    "                    epochs= 23,\n",
    "                    batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7b336ea6-b939-4c24-bd56-fa264e4b18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9962 - loss: 0.0168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.014589677564799786, 0.9966999888420105]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_3_layers.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762355e-fd05-45d6-b2be-322e06f794c8",
   "metadata": {},
   "source": [
    "<h4> Saving the trained model </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e56969-be1d-4bc5-ac4f-b5384c1912fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this line and run it to save the trained model. \n",
    "\n",
    "#full_model_3_layers.save(\"mnist_cnn_model_9966_pcnt.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc7272-26e9-43ba-b391-906a6f2091da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87b5b0-8fbc-46ba-b154-bf69610bd6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c3dfb-dd07-4923-915b-cf823be291d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-gpu]",
   "language": "python",
   "name": "conda-env-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
